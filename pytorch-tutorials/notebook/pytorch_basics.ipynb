{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch basics\n",
    "+ Author: xiaoran\n",
    "+ Time: p.m. 2019-01-17 \n",
    "\n",
    "展示pytorch的自动求导机制，和与numpy之间的交互\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 自动求导的例子1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# 1. 使用变量创建tensor，可以使用向量创建\n",
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# 2. 建立一个图表达式，torch会帮我们构建一个图\n",
    "# 默认的表达式是 y = 2 * x + 3\n",
    "y = w * x + b \n",
    "\n",
    "# 3. 计算y关于所有变量(x, w, b)的梯度\n",
    "y.backward()\n",
    "\n",
    "# 4. 打印出所有的梯度\n",
    "print(x.grad)    # x.grad = w = 2\n",
    "print(w.grad)    # w.grad = x = 1\n",
    "print(b.grad)    # b.grad = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 自动求导例子2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[-0.1595, -0.4917,  0.1873],\n",
      "        [ 0.0073, -0.4014, -0.0299]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([-0.2682, -0.3715], requires_grad=True)\n",
      "dL/dw:  tensor([[ 0.1115, -0.4553,  0.9870],\n",
      "        [ 0.0586, -0.3679,  0.4290]])\n",
      "dL/db:  tensor([-0.4715, -0.9214])\n",
      "loss after 1 step optimization:  1.4574180841445923\n"
     ]
    }
   ],
   "source": [
    "# 1. 随机创建二维的tensor，shape input x (10,2) and output y (10, 2)\n",
    "x = torch.randn(10, 3)\n",
    "y = torch.randn(10, 2)\n",
    "\n",
    "# 2. 建立一个全连接层， y = w * x + b, w 是权重 shape (3, 2)， b 是偏差 shape 2, 这是是默认参数还没有优化\n",
    "linear = nn.Linear(3, 2)\n",
    "print(\"w: \", linear.weight)\n",
    "print(\"b: \", linear.bias)\n",
    "\n",
    "# 3. 前面就是一个只有一层的MLP，定义损失函数和优化器\n",
    "loss_fun = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
    "\n",
    "# 4. 预测的时候就是，前向传播\n",
    "pred = linear(x)\n",
    "\n",
    "# 5. 计算损失\n",
    "loss = loss_fun(pred, y)\n",
    "\n",
    "# 6. 根据loss的反向传播，求导优化参数\n",
    "loss.backward()\n",
    "\n",
    "# 6.1. 打印出损失函数的梯度\n",
    "print(\"dL/dw: \", linear.weight.grad)\n",
    "print(\"dL/db: \", linear.bias.grad)\n",
    "# 7. 梯度下降, 使用学习率 0.01, 这里值执行一部\n",
    "optimizer.step()\n",
    "# 7.1 上面的基于优化函数的梯度下降，可以用下面的两句替代\n",
    "# linear.weight.data,sub_(0.01 * linear.weight.grad.data)\n",
    "# linear.bias.data,sub_(0.01 * linear.bias.grad.data)\n",
    "\n",
    "# 8. 打印执行一次梯度下降的损失函数\n",
    "pred = linear(x)\n",
    "loss = loss_fun(pred, y)\n",
    "print(\"loss after 1 step optimization: \", loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "循环方式进行梯度优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 step optimization: 0.48850151896476746\n",
      "loss after 2 step optimization: 0.49428820610046387\n",
      "loss after 3 step optimization: 0.5042358636856079\n",
      "loss after 4 step optimization: 0.5182933211326599\n",
      "loss after 5 step optimization: 0.5361483693122864\n",
      "loss after 6 step optimization: 0.5572361946105957\n",
      "loss after 7 step optimization: 0.5807634592056274\n",
      "loss after 8 step optimization: 0.6057454943656921\n",
      "loss after 9 step optimization: 0.6310566067695618\n",
      "loss after 10 step optimization: 0.6554887890815735\n"
     ]
    }
   ],
   "source": [
    "iter_k = 10\n",
    "for i in range(iter_k):\n",
    "    # 4. 预测的时候就是，前向传播\n",
    "    pred = linear(x)\n",
    "\n",
    "    # 5. 计算损失\n",
    "    loss = loss_fun(pred, y)\n",
    "\n",
    "    print(\"loss after %d step optimization: %s\" % (i+1, loss.item()))\n",
    "\n",
    "    # 6. 根据loss的反向传播，求导优化参数\n",
    "    loss.backward()\n",
    "\n",
    "    # 6.1. 打印出损失函数的梯度\n",
    "#     print(\"dL/dw: \", linear.weight.grad)\n",
    "#     print(\"dL/db: \", linear.bias.grad)\n",
    "    # 7. 梯度下降, 使用学习率 0.01, 这里值执行一部\n",
    "    optimizer.step()\n",
    "    # 7.1 上面的基于优化函数的梯度下降，可以用下面的两句替代\n",
    "    # linear.weight.data,sub_(0.01 * linear.weight.grad.data)\n",
    "    # linear.bias.data,sub_(0.01 * linear.bias.grad.data)\n",
    "\n",
    "    # 8. 打印执行一次梯度下降的损失函数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 从numpy中得到数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array\n",
    "x = np.array([[1,2],[3,4]])\n",
    "\n",
    "# convert numpy array to a touch tensor\n",
    "y = torch.from_numpy(x)\n",
    "\n",
    "# convert the torch tensor to a numpy array\n",
    "z = y.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Input pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n",
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Download and construct CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"../data/\",\n",
    "                                             train=True,\n",
    "                                             transform=transforms.ToTensor(),\n",
    "                                             download=True)\n",
    "image, label = train_dataset[0]\n",
    "print(image.size())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 8, 2, 7, 2, 1, 6, 6, 8, 9, 4, 9, 9, 0, 2, 9, 4, 7, 7, 6, 9, 1, 8, 3,\n",
      "        3, 1, 2, 8, 6, 3, 3, 7, 8, 4, 5, 3, 2, 9, 3, 5, 4, 0, 7, 5, 4, 3, 2, 1,\n",
      "        0, 6, 4, 1, 0, 8, 3, 0, 4, 1, 1, 0, 6, 0, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 数据架子（pytorch提供多线程和队列加载）\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 当迭代开始的时候，队列和多线程开始从文件中加载数据\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# 每次得到小批量的数据和label\n",
    "images, labels = data_iter.next()\n",
    "print(labels)\n",
    "\n",
    "# 在实际的使用时候，一般用for循环\n",
    "for images, labels in train_loader:\n",
    "    # Train code should be written here.\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Input pipline for custom dataset(自定制数据集)\n",
    "1. 使用下面给出的类参考的格式定义自己任务的数据\n",
    "2. 之后，使用上面的的方式，指定batch_size,\n",
    "3. 使用for循环或者iter的next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定制自己的客户数据集\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        # TODO\n",
    "        # 1. Initialize file paths or a list of file namse\n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform)\n",
    "        # 3. Return a data pair (e.g. image and label)\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # the total size of your dataset\n",
    "        size = 100\n",
    "        return size\n",
    "# 使用方式\n",
    "custom_dataset = CustomDataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 基于迁移学习的预训练模型\n",
    "1. 例子 resnet-18\n",
    "2. 去掉顶层网络，根据自己的数据重新定义\n",
    "3. 设置层的状态是否支持微调\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1315, -0.3085, -0.3245,  ...,  0.8461, -0.3385,  0.4021],\n",
      "        [-0.0519,  0.0103, -0.3423,  ...,  0.2445, -0.6687, -0.3538],\n",
      "        [-0.1635,  0.3438, -0.1041,  ...,  0.7054, -0.1408, -0.5326],\n",
      "        ...,\n",
      "        [-0.0605,  0.0587,  0.2331,  ...,  0.1945, -0.1341, -0.7930],\n",
      "        [ 0.0506, -0.0758, -0.2704,  ..., -0.6851, -0.0645, -0.0620],\n",
      "        [ 0.2934,  0.9082, -0.0303,  ...,  1.0034, -0.1470, -0.7424]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Download and load the pretrained ReNet-18. 下载并预训练模型\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# 设置参数，仅仅微调顶层，将其他层冻结\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the top layer for finetunig(根据自己的数据替换顶层网络结构，并记性微调)\n",
    "label_size = 100 # 你的数据的类别的个数\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, label_size)\n",
    "\n",
    "# Forward pass, 前向传播(这里可以设置epoch，batch，iteator)\n",
    "images = torch.randn(64, 3, 224, 224)\n",
    "outputs = resnet(images)\n",
    "print(outputs) # (64, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. save and load the entire model. (保存和加载模型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the entir model, (保存加载整个模型)\n",
    "torch.save(resnet, \"resnet_model.ckpt\")\n",
    "model = torch.load(\"resnet_model.ckpt\")\n",
    "\n",
    "# Save and load only the model parameters (recommend) 推荐仅仅保存模型的参数\n",
    "torch.save(resnet.state_dict(), \"resnet_params.ckpt\")\n",
    "resnet.load_state_dict(torch.load(\"resnet_params.ckpt\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
